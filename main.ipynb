{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''In tis main file we do an initial explortation, we clean the data, and perfoirm EDA and vizualisation'''\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import initial_exploration as explo\n",
    "import data_cleaning as cl\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets:\n",
    "cash_requests = pd.read_csv('project_dataset/extract - cash request - data analyst.csv')\n",
    "fees = pd.read_csv('project_dataset/extract - fees - data analyst - .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cash_requests.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inital exploration:\n",
    "explo.check(cash_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.convert_dates(cash_requests, cl.cash_request_date_columns)\n",
    "\n",
    "# Re-check and ensure correct data types in cash_requests:\n",
    "cl.ensure_correct_data_types(cash_requests, cl.cash_request_date_columns)\n",
    "\n",
    "cash_requests.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explo.check(cash_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explo.check(fees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.convert_dates(fees, cl.fees_data_date_columns)\n",
    "\n",
    "# Re-check and ensure correct data types in cfees:\n",
    "cl.ensure_correct_data_types(fees, cl.fees_data_date_columns)\n",
    "\n",
    "fees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.rename_col(cash_requests, 'id', 'cash_request_id')\n",
    "data_df = cl.merge_df(cash_requests, fees, 'outer', 'cash_request_id')\n",
    "data_df = cl.rename_col_xy(data_df)\n",
    "data_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.rename_col(data_df, 'id', 'id_fee')\n",
    "cl.clean_text_column(data_df, \"reason\")\n",
    "explo.check(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = cl.remove_nan(data_df, \"cash_request_id\")\n",
    "explo.check_null(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = cl.drop_col(data_df, [\"id_fee\", \"category\"])\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explo.check_null(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = cl.selecting_data_types(data_df)\n",
    "num = frames[1]\n",
    "cat = frames[0]\n",
    "date = frames[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explo.check_null(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explo.check_null(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explo.check_null(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify specific date columns' data types in cash_requests:\n",
    "print(\"\\nCheck data types of date columns:\")\n",
    "print(cash_requests[['created_at', 'updated_at', 'moderated_at', 'reimbursement_date', \n",
    "                     'cash_request_received_date', 'money_back_date', 'send_at', 'reco_creation', 'reco_last_update']].dtypes)\n",
    "\n",
    "# Check for any NaT in date columns:\n",
    "print(\"\\nCheck NaT (missing values) in date columns:\")\n",
    "print(cash_requests[['created_at', 'updated_at', 'moderated_at', 'reimbursement_date', \n",
    "                     'cash_request_received_date', 'money_back_date', 'send_at', 'reco_creation', 'reco_last_update']].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_between_CR_and_money_back = cl.process_date_columns(date, \"CR_created_at\", \"money_back_date\")\n",
    "df_time_between_CR_and_money_back.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explo.check(df_time_between_CR_and_money_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_between_fee_created_and_paid_at_date = cl.process_date_columns(date, \"fee_created_at\", \"paid_at\")\n",
    "df_time_between_fee_created_and_paid_at_date.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explo.check(df_time_between_fee_created_and_paid_at_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can divide the columns between us and ecah work in a set of columns performing an \n",
    "# univariate analysis (frequency plots, box plots, doughnut, histograms   or any other you concider)\n",
    "#For numercial plots also create report in mean , meadian, std, and arrive to conclusions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cat.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_dates = cat[~cat['charge_moment'].apply(pd.to_datetime, errors='coerce').notna()]\n",
    "print(invalid_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_count = cat[cat['charge_moment'].isna()].shape[0]\n",
    "print(f'Number of rows with missing charge_moment: {missing_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'charge_moment' is in datetime format, handle invalid date strings by converting them to NaT\n",
    "cat['charge_moment'] = pd.to_datetime(cat['charge_moment'], errors='coerce')\n",
    "\n",
    "# Step 1: Define cohorts based on the month of the first cash request\n",
    "cat['cohort_month'] = cat['charge_moment'].dt.to_period('M')\n",
    "\n",
    "# Step 2: Clean the 'reason' column (strip whitespace and convert to lowercase)\n",
    "cat['reason'] = cat['reason'].str.strip().str.lower()\n",
    "\n",
    "# Step 3: Define payment incident reasons (in lowercase)\n",
    "incident_reasons = ['rejected direct debit', 'month delay on payment']\n",
    "\n",
    "# Step 4: Filter rows where 'reason' matches one of the incident reasons, and drop NaN values\n",
    "incident_data = cat[cat['reason'].isin(incident_reasons)].dropna(subset=['reason'])\n",
    "\n",
    "# Check if any incidents are found after filtering\n",
    "if incident_data.empty:\n",
    "    print(\"Incident data is empty. Inspecting data:\")\n",
    "    print(cat[['reason', 'cohort_month']].head(20))  # Check the first 20 rows for any reason matches\n",
    "\n",
    "# Step 5: Group by cohort (cohort_month) and calculate the number of incidents for each cohort\n",
    "incident_rate = incident_data.groupby('cohort_month').size().reset_index(name='incident_count')\n",
    "\n",
    "# Step 6: Count the total number of requests for each cohort (including both completed and incomplete requests)\n",
    "total_requests = cat.groupby('cohort_month').size().reset_index(name='total_requests')\n",
    "\n",
    "# Step 7: Merge the incident count and total requests data\n",
    "cohort_data = pd.merge(incident_rate, total_requests, on='cohort_month', how='left')\n",
    "\n",
    "# Step 8: Calculate incident rate (number of incidents divided by the total number of requests in that cohort)\n",
    "cohort_data['incident_rate'] = cohort_data['incident_count'] / cohort_data['total_requests']\n",
    "\n",
    "# Step 9: Fill any missing values in incident_count with 0 (no incidents for that cohort)\n",
    "cohort_data['incident_count'] = cohort_data['incident_count'].fillna(0)\n",
    "\n",
    "# Display the results\n",
    "print(cohort_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in the 'reason' column\n",
    "print(cat['reason'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for incidents by filtering directly on 'reason'\n",
    "incident_data_check = cat[cat['reason'].isin(incident_reasons)]\n",
    "print(incident_data_check.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any NaT values in 'charge_moment'\n",
    "print(cat[cat['charge_moment'].isna()])  # Rows where charge_moment could not be converted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the 'reason' column\n",
    "print(cat[cat['reason'].isna()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the total number of requests per cohort\n",
    "total_requests_check = cat.groupby('cohort_month').size().reset_index(name='total_requests')\n",
    "print(total_requests_check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle NaT values by dropping rows with missing 'charge_moment' and reattempt cohort calculation\n",
    "\n",
    "# Drop rows where 'charge_moment' is NaT (you can also choose to fill them as needed)\n",
    "cat_cleaned = cat.dropna(subset=['charge_moment'])\n",
    "\n",
    "# Ensure 'charge_moment' is in datetime format, if needed\n",
    "cat_cleaned['charge_moment'] = pd.to_datetime(cat_cleaned['charge_moment'], errors='coerce')\n",
    "\n",
    "# Define cohorts based on the month of the first cash request\n",
    "cat_cleaned['cohort_month'] = cat_cleaned['charge_moment'].dt.to_period('M')\n",
    "\n",
    "# Calculate the number of requests per cohort\n",
    "cohort_data = cat_cleaned.groupby('cohort_month').agg(\n",
    "    total_requests=('charge_moment', 'size')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate incident rate by dividing the count of incidents by the total number of requests for each cohort\n",
    "cat_cleaned['incident'] = cat_cleaned['reason'].apply(lambda x: 1 if pd.notna(x) else 0)\n",
    "cohort_data['incident_count'] = cat_cleaned.groupby('cohort_month')['incident'].sum().reset_index()['incident']\n",
    "\n",
    "# Calculate incident rate\n",
    "cohort_data['incident_rate'] = cohort_data['incident_count'] / cohort_data['total_requests']\n",
    "\n",
    "# Display the cohort data\n",
    "print(cohort_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Drop rows where 'charge_moment' is NaT\n",
    "cat_cleaned = cat.dropna(subset=['charge_moment'])\n",
    "\n",
    "# Step 2: Convert 'charge_moment' to datetime format\n",
    "cat_cleaned['charge_moment'] = pd.to_datetime(cat_cleaned['charge_moment'], errors='coerce')\n",
    "\n",
    "# Step 3: Check if there are any valid 'charge_moment' values after conversion\n",
    "print(f\"Rows with valid 'charge_moment': {cat_cleaned['charge_moment'].notna().sum()}\")\n",
    "\n",
    "# Step 4: Check if the 'reason' column has any non-NaN values (for incident calculation)\n",
    "print(f\"Rows with valid 'reason': {cat_cleaned['reason'].notna().sum()}\")\n",
    "\n",
    "# Step 5: Create a new 'incident' column based on the 'reason'\n",
    "cat_cleaned['incident'] = cat_cleaned['reason'].apply(lambda x: 1 if pd.notna(x) else 0)\n",
    "\n",
    "# Step 6: Create cohorts based on the month of the first cash request\n",
    "cat_cleaned['cohort_month'] = cat_cleaned['charge_moment'].dt.to_period('M')\n",
    "\n",
    "# Step 7: Group by 'cohort_month' and calculate total requests and incident counts\n",
    "cohort_data = cat_cleaned.groupby('cohort_month').agg(\n",
    "    total_requests=('charge_moment', 'size'),\n",
    "    incident_count=('incident', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Step 8: Calculate incident rate (incident count / total requests)\n",
    "cohort_data['incident_rate'] = cohort_data['incident_count'] / cohort_data['total_requests']\n",
    "\n",
    "# Step 9: Check if cohort_data has rows\n",
    "print(f\"Cohort data rows: {cohort_data.shape[0]}\")\n",
    "\n",
    "# Display the result\n",
    "print(cohort_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Inspect the first few rows of the dataset\n",
    "print(\"First few rows of the data:\")\n",
    "print(cat.head())\n",
    "\n",
    "# Step 2: Check if 'charge_moment' and 'reason' columns are truly empty\n",
    "print(\"\\nCheck for NaN values in 'charge_moment' and 'reason':\")\n",
    "print(f\"NaN in 'charge_moment': {cat['charge_moment'].isna().sum()} out of {len(cat)}\")\n",
    "print(f\"NaN in 'reason': {cat['reason'].isna().sum()} out of {len(cat)}\")\n",
    "\n",
    "# Step 3: Check unique values in 'charge_moment' and 'reason' to see if they are populated or have issues\n",
    "print(\"\\nUnique values in 'charge_moment':\")\n",
    "print(cat['charge_moment'].unique())\n",
    "\n",
    "print(\"\\nUnique values in 'reason':\")\n",
    "print(cat['reason'].unique())\n",
    "\n",
    "# Step 4: Check the data types of these columns to ensure they are as expected\n",
    "print(\"\\nData types of columns:\")\n",
    "print(cat[['charge_moment', 'reason']].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: If charge_moment is NaT for all rows, create a cohort_month column based on the current date\n",
    "cat['cohort_month'] = pd.to_datetime('now').strftime('%Y-%m')\n",
    "\n",
    "# Step 2: Filter the dataframe where 'reason' is not NaN\n",
    "filtered_data = cat[cat['reason'].notna()]\n",
    "\n",
    "# Step 3: Group by 'cohort_month' and 'reason' and calculate total requests and incident count\n",
    "cohort_data = filtered_data.groupby(['cohort_month', 'reason']).size().reset_index(name='total_requests')\n",
    "\n",
    "# Step 4: Count the incidents by grouping on 'reason' (assuming each reason corresponds to an incident)\n",
    "incident_data = filtered_data.groupby(['cohort_month', 'reason']).size().reset_index(name='incident_count')\n",
    "\n",
    "# Step 5: Merge the data to get total_requests and incident_count in one dataframe\n",
    "cohort_data = pd.merge(cohort_data, incident_data, on=['cohort_month', 'reason'], how='left')\n",
    "\n",
    "# Step 6: Calculate the incident rate\n",
    "cohort_data['incident_rate'] = cohort_data['incident_count'] / cohort_data['total_requests']\n",
    "\n",
    "# Display the final cohort data\n",
    "print(cohort_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
