{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''In tis main file we do an initial explortation, we clean the data, and perfoirm EDA and vizualisation'''\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import initial_exploration as explo\n",
    "import data_cleaning as cl\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets:\n",
    "cash_requests = pd.read_csv('project_dataset/extract - cash request - data analyst.csv')\n",
    "fees = pd.read_csv('project_dataset/extract - fees - data analyst - .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cash_requests.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inital exploration:\n",
    "explo.check(cash_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.convert_dates(cash_requests, cl.cash_request_date_columns)\n",
    "\n",
    "# Re-check and ensure correct data types in cash_requests:\n",
    "cl.ensure_correct_data_types(cash_requests, cl.cash_request_date_columns)\n",
    "\n",
    "cash_requests.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explo.check(cash_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explo.check(fees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.convert_dates(fees, cl.fees_data_date_columns)\n",
    "\n",
    "# Re-check and ensure correct data types in cfees:\n",
    "cl.ensure_correct_data_types(fees, cl.fees_data_date_columns)\n",
    "\n",
    "fees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.rename_col(cash_requests, 'id', 'cash_request_id')\n",
    "data_df = cl.merge_df(cash_requests, fees, 'outer', 'cash_request_id')\n",
    "data_df = cl.rename_col_xy(data_df)\n",
    "data_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.rename_col(data_df, 'id', 'id_fee')\n",
    "cl.clean_text_column(data_df, \"reason\")\n",
    "explo.check(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = cl.remove_nan(data_df, \"cash_request_id\")\n",
    "explo.check_null(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = cl.drop_col(data_df, [\"id_fee\", \"category\"])\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explo.check_null(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = cl.selecting_data_types(data_df)\n",
    "num = frames[1]\n",
    "cat = frames[0]\n",
    "date = frames[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explo.check_null(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explo.check_null(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explo.check_null(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify specific date columns' data types in cash_requests:\n",
    "print(\"\\nCheck data types of date columns:\")\n",
    "print(cash_requests[['created_at', 'updated_at', 'moderated_at', 'reimbursement_date', \n",
    "                     'cash_request_received_date', 'money_back_date', 'send_at', 'reco_creation', 'reco_last_update']].dtypes)\n",
    "\n",
    "# Check for any NaT in date columns:\n",
    "print(\"\\nCheck NaT (missing values) in date columns:\")\n",
    "print(cash_requests[['created_at', 'updated_at', 'moderated_at', 'reimbursement_date', \n",
    "                     'cash_request_received_date', 'money_back_date', 'send_at', 'reco_creation', 'reco_last_update']].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_between_CR_and_money_back = cl.process_date_columns(date, \"CR_created_at\", \"money_back_date\")\n",
    "df_time_between_CR_and_money_back.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explo.check(df_time_between_CR_and_money_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_between_fee_created_and_paid_at_date = cl.process_date_columns(date, \"fee_created_at\", \"paid_at\")\n",
    "df_time_between_fee_created_and_paid_at_date.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explo.check(df_time_between_fee_created_and_paid_at_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can divide the columns between us and ecah work in a set of columns performing an \n",
    "# univariate analysis (frequency plots, box plots, doughnut, histograms   or any other you concider)\n",
    "#For numercial plots also create report in mean , meadian, std, and arrive to conclusions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cat.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_dates = cat[~cat['charge_moment'].apply(pd.to_datetime, errors='coerce').notna()]\n",
    "print(invalid_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_count = cat[cat['charge_moment'].isna()].shape[0]\n",
    "print(f'Number of rows with missing charge_moment: {missing_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'charge_moment' to datetime (already done in your previous steps)\n",
    "cat['charge_moment'] = pd.to_datetime(cat['charge_moment'], errors='coerce')\n",
    "\n",
    "# Calculate the median date of valid entries\n",
    "median_date = cat['charge_moment'].dropna().median()\n",
    "\n",
    "# Fill missing or invalid dates with the median\n",
    "cat['charge_moment'] = cat['charge_moment'].fillna(median_date)\n",
    "\n",
    "# Optionally: check the median date you calculated\n",
    "print(f\"Median date for imputation: {median_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure 'charge_moment' is in datetime format\n",
    "cat['charge_moment'] = pd.to_datetime(cat['charge_moment'])\n",
    "\n",
    "# Step 1: Define cohorts based on the month of the first cash request\n",
    "cat['cohort_month'] = cat['charge_moment'].dt.to_period('M')\n",
    "\n",
    "# Step 2: Clean the 'reason' column (strip whitespace and convert to lowercase)\n",
    "cat['reason'] = cat['reason'].str.strip().str.lower()\n",
    "\n",
    "# Step 3: Define payment incident reasons (in lowercase)\n",
    "incident_reasons = ['rejected direct debit', 'month delay on payment']\n",
    "\n",
    "# Step 4: Filter rows where 'reason' matches one of the incident reasons, and drop NaN values\n",
    "incident_data = cat[cat['reason'].isin(incident_reasons)].dropna(subset=['reason'])\n",
    "\n",
    "# Check if any incidents are found after filtering\n",
    "if incident_data.empty:\n",
    "    print(\"Incident data is empty. Inspecting data:\")\n",
    "    print(cat[['reason', 'cohort_month']].head(20))  # Check the first 20 rows for any reason matches\n",
    "\n",
    "# Step 5: Group by cohort (cohort_month) and calculate the number of incidents for each cohort\n",
    "incident_rate = incident_data.groupby('cohort_month').size().reset_index(name='incident_count')\n",
    "\n",
    "# Step 6: Count the total number of requests for each cohort (including both completed and incomplete requests)\n",
    "total_requests = cat.groupby('cohort_month').size().reset_index(name='total_requests')\n",
    "\n",
    "# Step 7: Merge the incident count and total requests data\n",
    "cohort_data = pd.merge(incident_rate, total_requests, on='cohort_month', how='left')\n",
    "\n",
    "# Step 8: Calculate incident rate (number of incidents divided by the total number of requests in that cohort)\n",
    "cohort_data['incident_rate'] = cohort_data['incident_count'] / cohort_data['total_requests']\n",
    "\n",
    "# Step 9: Fill any missing values in incident_count with 0 (no incidents for that cohort)\n",
    "cohort_data['incident_count'] = cohort_data['incident_count'].fillna(0)\n",
    "\n",
    "# Display the results\n",
    "print(cohort_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
